<details>
  <summary><b>TOC</b></summary>
  <ol>
    <li><a href=#sfm>SFM</a></li>
      <ul>
        <li><a href=#Dense-Point-Clouds-Matter:-Dust-GS-for-Scene-Reconstruction-from-Sparse-Viewpoints>Dense Point Clouds Matter: Dust-GS for Scene Reconstruction from Sparse Viewpoints</a></li>
      </ul>
    </li>
    <li><a href=#keypoint-detection>Keypoint Detection</a></li>
      <ul>
        <li><a href=#Precision-Aquaculture:-An-Integrated-Computer-Vision-and-IoT-Approach-for-Optimized-Tilapia-Feeding>Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding</a></li>
      </ul>
    </li>
  </ol>
</details>

## SFM  

### [Dense Point Clouds Matter: Dust-GS for Scene Reconstruction from Sparse Viewpoints](http://arxiv.org/abs/2409.08613)  
Shan Chen, Jiale Zhou, Lei Li  
<details>  
  <summary>Abstract</summary>  
  <ol>  
    3D Gaussian Splatting (3DGS) has demonstrated remarkable performance in scene synthesis and novel view synthesis tasks. Typically, the initialization of 3D Gaussian primitives relies on point clouds derived from Structure-from-Motion (SfM) methods. However, in scenarios requiring scene reconstruction from sparse viewpoints, the effectiveness of 3DGS is significantly constrained by the quality of these initial point clouds and the limited number of input images. In this study, we present Dust-GS, a novel framework specifically designed to overcome the limitations of 3DGS in sparse viewpoint conditions. Instead of relying solely on SfM, Dust-GS introduces an innovative point cloud initialization technique that remains effective even with sparse input data. Our approach leverages a hybrid strategy that integrates an adaptive depth-based masking technique, thereby enhancing the accuracy and detail of reconstructed scenes. Extensive experiments conducted on several benchmark datasets demonstrate that Dust-GS surpasses traditional 3DGS methods in scenarios with sparse viewpoints, achieving superior scene reconstruction quality with a reduced number of input images.  
  </ol>  
</details>  
  
  



## Keypoint Detection  

### [Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding](http://arxiv.org/abs/2409.08695)  
Rania Hossam, Ahmed Heakl, Walid Gomaa  
<details>  
  <summary>Abstract</summary>  
  <ol>  
    Traditional fish farming practices often lead to inefficient feeding, resulting in environmental issues and reduced productivity. We developed an innovative system combining computer vision and IoT technologies for precise Tilapia feeding. Our solution uses real-time IoT sensors to monitor water quality parameters and computer vision algorithms to analyze fish size and count, determining optimal feed amounts. A mobile app enables remote monitoring and control. We utilized YOLOv8 for keypoint detection to measure Tilapia weight from length, achieving \textbf{94\%} precision on 3,500 annotated images. Pixel-based measurements were converted to centimeters using depth estimation for accurate feeding calculations. Our method, with data collection mirroring inference conditions, significantly improved results. Preliminary estimates suggest this approach could increase production up to 58 times compared to traditional farms. Our models, code, and dataset are open-source~\footnote{The code, dataset, and models are available upon reasonable request.  
  </ol>  
</details>  
**comments**: 8 pages, 6 figures, 3 tables, 21th International Conference on
  Informatics in Control, Automation, and Robotics  
  
  



