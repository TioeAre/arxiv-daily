{"SFM": {"2408.01035": {"paper_title": "Structure from Motion-based Motion Estimation and 3D Reconstruction of Unknown Shaped Space Debris", "paper_abstract": "With the boost in the number of spacecraft launches in the current decades, the space debris problem is daily becoming significantly crucial. For sustainable space utilization, the continuous removal of space debris is the most severe problem for humanity. To maximize the reliability of the debris capture mission in orbit, accurate motion estimation of the target is essential. Space debris has lost its attitude and orbit control capabilities, and its shape is unknown due to the break. This paper proposes the Structure from Motion-based algorithm to perform unknown shaped space debris motion estimation with limited resources, where only 2D images are required as input. The method then outputs the reconstructed shape of the unknown object and the relative pose trajectory between the target and the camera simultaneously, which are exploited to estimate the target's motion. The method is quantitatively validated with the realistic image dataset generated by the microgravity experiment in a 2D air-floating testbed and 3D kinematic simulation.", "paper_authors": "Kentaro Uno, Takehiro Matsuoka, Akiyoshi Uchida, Kazuya Yoshida", "update_time": "2024-08-02", "comments": "6 pages, 10 figures. Manuscript accepted at the 2024 IEEE 20th\n  International Conference on Automation Science and Engineerin (CASE 2024)", "paper_url": "http://arxiv.org/abs/2408.01035", "paper_id": "2408.01035", "code_url": null}}, "NeRF": {"2408.01251": {"paper_title": "NeRFoot: Robot-Footprint Estimation for Image-Based Visual Servoing", "paper_abstract": "This paper investigates the utility of Neural Radiance Fields (NeRF) models in extending the regions of operation of a mobile robot, controlled by Image-Based Visual Servoing (IBVS) via static CCTV cameras. Using NeRF as a 3D-representation prior, the robot's footprint may be extrapolated geometrically and used to train a CNN-based network to extract it online from the robot's appearance alone. The resulting footprint results in a tighter bound than a robot-wide bounding box, allowing the robot's controller to prescribe more optimal trajectories and expand its safe operational floor area.", "paper_authors": "Daoxin Zhong, Luke Robinson, Daniele De Martini", "update_time": "2024-08-02", "comments": null, "paper_url": "http://arxiv.org/abs/2408.01251", "paper_id": "2408.01251", "code_url": null}, "2408.00860": {"paper_title": "UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization", "paper_abstract": "Three-dimensional ultrasound imaging is a critical technology widely used in medical diagnostics. However, traditional 3D ultrasound imaging methods have limitations such as fixed resolution, low storage efficiency, and insufficient contextual connectivity, leading to poor performance in handling complex artifacts and reflection characteristics. Recently, techniques based on NeRF (Neural Radiance Fields) have made significant progress in view synthesis and 3D reconstruction, but there remains a research gap in high-quality ultrasound imaging. To address these issues, we propose a new model, UlRe-NeRF, which combines implicit neural networks and explicit ultrasound volume rendering into an ultrasound neural rendering architecture. This model incorporates reflection direction parameterization and harmonic encoding, using a directional MLP module to generate view-dependent high-frequency reflection intensity estimates, and a spatial MLP module to produce the medium's physical property parameters. These parameters are used in the volume rendering process to accurately reproduce the propagation and reflection behavior of ultrasound waves in the medium. Experimental results demonstrate that the UlRe-NeRF model significantly enhances the realism and accuracy of high-fidelity ultrasound image reconstruction, especially in handling complex medium structures.", "paper_authors": "Ziwen Guo, Zi Fang, Zhuang Fu", "update_time": "2024-08-01", "comments": null, "paper_url": "http://arxiv.org/abs/2408.00860", "paper_id": "2408.00860", "code_url": null}}}