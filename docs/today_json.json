{"Visual Localization": {"2412.18136": {"paper_title": "ERVD: An Efficient and Robust ViT-Based Distillation Framework for Remote Sensing Image Retrieval", "paper_abstract": "ERVD: An Efficient and Robust ViT-Based Distillation Framework for Remote Sensing Image Retrieval", "paper_authors": "Le Dong, Qixuan Cao, Lei Pu, Fangfang Wu, Weisheng Dong, Xin Li, Guangming Shi", "update_time": "2024-12-24", "comments": null, "paper_url": "http://arxiv.org/abs/2412.18136", "paper_id": "2412.18136", "code_url": "https://github.com/milkyfun0/ERVD"}}, "Keypoint Detection": {"2412.18221": {"paper_title": "GIMS: Image Matching System Based on Adaptive Graph Construction and Graph Neural Network", "paper_abstract": "Feature-based image matching has extensive applications in computer vision. Keypoints detected in images can be naturally represented as graph structures, and Graph Neural Networks (GNNs) have been shown to outperform traditional deep learning techniques. Consequently, the paradigm of image matching via GNNs has gained significant prominence in recent academic research. In this paper, we first introduce an innovative adaptive graph construction method that utilizes a filtering mechanism based on distance and dynamic threshold similarity. This method dynamically adjusts the criteria for incorporating new vertices based on the characteristics of existing vertices, allowing for the construction of more precise and robust graph structures while avoiding redundancy. We further combine the vertex processing capabilities of GNNs with the global awareness capabilities of Transformers to enhance the model's representation of spatial and feature information within graph structures. This hybrid model provides a deeper understanding of the interrelationships between vertices and their contributions to the matching process. Additionally, we employ the Sinkhorn algorithm to iteratively solve for optimal matching results. Finally, we validate our system using extensive image datasets and conduct comprehensive comparative experiments. Experimental results demonstrate that our system achieves an average improvement of 3.8x-40.3x in overall matching performance. Additionally, the number of vertices and edges significantly impacts training efficiency and memory usage; therefore, we employ multi-GPU technology to accelerate the training process. Our code is available at https://github.com/songxf1024/GIMS.", "paper_authors": "Xianfeng Song, Yi Zou, Zheng Shi, Zheng Liu", "update_time": "2024-12-24", "comments": null, "paper_url": "http://arxiv.org/abs/2412.18221", "paper_id": "2412.18221", "code_url": "https://github.com/songxf1024/gims"}}, "Image Matching": {"2412.18221": {"paper_title": "GIMS: Image Matching System Based on Adaptive Graph Construction and Graph Neural Network", "paper_abstract": "Feature-based image matching has extensive applications in computer vision. Keypoints detected in images can be naturally represented as graph structures, and Graph Neural Networks (GNNs) have been shown to outperform traditional deep learning techniques. Consequently, the paradigm of image matching via GNNs has gained significant prominence in recent academic research. In this paper, we first introduce an innovative adaptive graph construction method that utilizes a filtering mechanism based on distance and dynamic threshold similarity. This method dynamically adjusts the criteria for incorporating new vertices based on the characteristics of existing vertices, allowing for the construction of more precise and robust graph structures while avoiding redundancy. We further combine the vertex processing capabilities of GNNs with the global awareness capabilities of Transformers to enhance the model's representation of spatial and feature information within graph structures. This hybrid model provides a deeper understanding of the interrelationships between vertices and their contributions to the matching process. Additionally, we employ the Sinkhorn algorithm to iteratively solve for optimal matching results. Finally, we validate our system using extensive image datasets and conduct comprehensive comparative experiments. Experimental results demonstrate that our system achieves an average improvement of 3.8x-40.3x in overall matching performance. Additionally, the number of vertices and edges significantly impacts training efficiency and memory usage; therefore, we employ multi-GPU technology to accelerate the training process. Our code is available at https://github.com/songxf1024/GIMS.", "paper_authors": "Xianfeng Song, Yi Zou, Zheng Shi, Zheng Liu", "update_time": "2024-12-24", "comments": null, "paper_url": "http://arxiv.org/abs/2412.18221", "paper_id": "2412.18221", "code_url": "https://github.com/songxf1024/gims"}}}