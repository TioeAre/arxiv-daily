{"Visual Localization": {"2409.03012": {"paper_title": "Design and Evaluation of Camera-Centric Mobile Crowdsourcing Applications", "paper_abstract": "The data that underlies automated methods in computer vision and machine learning, such as image retrieval and fine-grained recognition, often comes from crowdsourcing. In contexts that rely on the intrinsic motivation of users, we seek to understand how the application design affects a user's willingness to contribute and the quantity and quality of the data they capture. In this project, we designed three versions of a camera-based mobile crowdsourcing application, which varied in the amount of labeling effort requested of the user and conducted a user study to evaluate the trade-off between the level of user-contributed information requested and the quantity and quality of labeled images collected. The results suggest that higher levels of user labeling do not lead to reduced contribution. Users collected and annotated the most images using the application version with the highest requested level of labeling with no decrease in user satisfaction. In preliminary experiments, the additional labeled data supported increased performance on an image retrieval task.", "paper_authors": "Abby Stylianou, Michelle Brachman, Albatool Wazzan, Samuel Black, Richard Souvenir", "update_time": "2024-09-04", "comments": null, "paper_url": "http://arxiv.org/abs/2409.03012", "paper_id": "2409.03012", "code_url": null}}, "Image Matching": {"2409.03568": {"paper_title": "Enabling Practical and Privacy-Preserving Image Processing", "paper_abstract": "Fully Homomorphic Encryption (FHE) enables computations on encrypted data, preserving confidentiality without the need for decryption. However, FHE is often hindered by significant performance overhead, particularly for high-precision and complex data like images. Due to serious efficiency issues, traditional FHE methods often encrypt images by monolithic data blocks (such as pixel rows), instead of pixels. However, this strategy compromises the advantages of homomorphic operations and disables pixel-level image processing. In this study, we address these challenges by proposing and implementing a pixel-level homomorphic encryption approach, iCHEETAH, based on the CKKS scheme. To enhance computational efficiency, we introduce three novel caching mechanisms to pre-encrypt radix values or frequently occurring pixel values, substantially reducing redundant encryption operations. Extensive experiments demonstrate that our approach achieves up to a 19-fold improvement in encryption speed compared to the original CKKS, while maintaining high image quality. Additionally, real-world image applications such as mean filtering, brightness enhancement, image matching and watermarking are tested based on FHE, showcasing up to a 91.53% speed improvement. We also proved that our method is IND-CPA (Indistinguishability under Chosen Plaintext Attack) secure, providing strong encryption security. These results underscore the practicality and efficiency of iCHEETAH, marking a significant advancement in privacy-preserving image processing at scale.", "paper_authors": "Chao Wang, Shubing Yang, Xiaoyan Sun, Jun Dai, Dongfang Zhao", "update_time": "2024-09-05", "comments": "16 pages, 10 figures", "paper_url": "http://arxiv.org/abs/2409.03568", "paper_id": "2409.03568", "code_url": null}, "2409.03032": {"paper_title": "A General Albedo Recovery Approach for Aerial Photogrammetric Images through Inverse Rendering", "paper_abstract": "Modeling outdoor scenes for the synthetic 3D environment requires the recovery of reflectance/albedo information from raw images, which is an ill-posed problem due to the complicated unmodeled physics in this process (e.g., indirect lighting, volume scattering, specular reflection). The problem remains unsolved in a practical context. The recovered albedo can facilitate model relighting and shading, which can further enhance the realism of rendered models and the applications of digital twins. Typically, photogrammetric 3D models simply take the source images as texture materials, which inherently embed unwanted lighting artifacts (at the time of capture) into the texture. Therefore, these polluted textures are suboptimal for a synthetic environment to enable realistic rendering. In addition, these embedded environmental lightings further bring challenges to photo-consistencies across different images that cause image-matching uncertainties. This paper presents a general image formation model for albedo recovery from typical aerial photogrammetric images under natural illuminations and derives the inverse model to resolve the albedo information through inverse rendering intrinsic image decomposition. Our approach builds on the fact that both the sun illumination and scene geometry are estimable in aerial photogrammetry, thus they can provide direct inputs for this ill-posed problem. This physics-based approach does not require additional input other than data acquired through the typical drone-based photogrammetric collection and was shown to favorably outperform existing approaches. We also demonstrate that the recovered albedo image can in turn improve typical image processing tasks in photogrammetry such as feature and dense matching, edge, and line extraction.", "paper_authors": "Shuang Song, Rongjun Qin", "update_time": "2024-09-04", "comments": "ISPRS Journal of Photogrammetry and Remote Sensing", "paper_url": "http://arxiv.org/abs/2409.03032", "paper_id": "2409.03032", "code_url": null}}, "NeRF": {"2409.03424": {"paper_title": "Weight Conditioning for Smooth Optimization of Neural Networks", "paper_abstract": "In this article, we introduce a novel normalization technique for neural network weight matrices, which we term weight conditioning. This approach aims to narrow the gap between the smallest and largest singular values of the weight matrices, resulting in better-conditioned matrices. The inspiration for this technique partially derives from numerical linear algebra, where well-conditioned matrices are known to facilitate stronger convergence results for iterative solvers. We provide a theoretical foundation demonstrating that our normalization technique smoothens the loss landscape, thereby enhancing convergence of stochastic gradient descent algorithms. Empirically, we validate our normalization across various neural network architectures, including Convolutional Neural Networks (CNNs), Vision Transformers (ViT), Neural Radiance Fields (NeRF), and 3D shape modeling. Our findings indicate that our normalization method is not only competitive but also outperforms existing weight normalization techniques from the literature.", "paper_authors": "Hemanth Saratchandran, Thomas X. Wang, Simon Lucey", "update_time": "2024-09-05", "comments": "ECCV 2024", "paper_url": "http://arxiv.org/abs/2409.03424", "paper_id": "2409.03424", "code_url": null}, "2409.03213": {"paper_title": "Optimizing 3D Gaussian Splatting for Sparse Viewpoint Scene Reconstruction", "paper_abstract": "3D Gaussian Splatting (3DGS) has emerged as a promising approach for 3D scene representation, offering a reduction in computational overhead compared to Neural Radiance Fields (NeRF). However, 3DGS is susceptible to high-frequency artifacts and demonstrates suboptimal performance under sparse viewpoint conditions, thereby limiting its applicability in robotics and computer vision. To address these limitations, we introduce SVS-GS, a novel framework for Sparse Viewpoint Scene reconstruction that integrates a 3D Gaussian smoothing filter to suppress artifacts. Furthermore, our approach incorporates a Depth Gradient Profile Prior (DGPP) loss with a dynamic depth mask to sharpen edges and 2D diffusion with Score Distillation Sampling (SDS) loss to enhance geometric consistency in novel view synthesis. Experimental evaluations on the MipNeRF-360 and SeaThru-NeRF datasets demonstrate that SVS-GS markedly improves 3D reconstruction from sparse viewpoints, offering a robust and efficient solution for scene understanding in robotics and computer vision applications.", "paper_authors": "Shen Chen, Jiale Zhou, Lei Li", "update_time": "2024-09-05", "comments": null, "paper_url": "http://arxiv.org/abs/2409.03213", "paper_id": "2409.03213", "code_url": null}}}