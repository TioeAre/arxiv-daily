{"SFM": {"2409.18673": {"paper_title": "Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras", "paper_abstract": "Dashboard cameras (dashcams) record millions of driving videos daily, offering a valuable potential data source for various applications, including driving map production and updates. A necessary step for utilizing these dashcam data involves the estimation of camera poses. However, the low-quality images captured by dashcams, characterized by motion blurs and dynamic objects, pose challenges for existing image-matching methods in accurately estimating camera poses. In this study, we propose a precise pose estimation method for dashcam images, leveraging the inherent camera motion prior. Typically, image sequences captured by dash cameras exhibit pronounced motion prior, such as forward movement or lateral turns, which serve as essential cues for correspondence estimation. Building upon this observation, we devise a pose regression module aimed at learning camera motion prior, subsequently integrating these prior into both correspondences and pose estimation processes. The experiment shows that, in real dashcams dataset, our method is 22% better than the baseline for pose estimation in AUC5\\textdegree, and it can estimate poses for 19% more images with less reprojection error in Structure from Motion (SfM).", "paper_authors": "Yipeng Lu, Yifan Zhao, Haiping Wang, Zhiwei Ruan, Yuan Liu, Zhen Dong, Bisheng Yang", "update_time": "2024-09-27", "comments": null, "paper_url": "http://arxiv.org/abs/2409.18673", "paper_id": "2409.18673", "code_url": null}}, "Visual Localization": {"2409.18733": {"paper_title": "Search and Detect: Training-Free Long Tail Object Detection via Web-Image Retrieval", "paper_abstract": "In this paper, we introduce SearchDet, a training-free long-tail object detection framework that significantly enhances open-vocabulary object detection performance. SearchDet retrieves a set of positive and negative images of an object to ground, embeds these images, and computes an input image-weighted query which is used to detect the desired concept in the image. Our proposed method is simple and training-free, yet achieves over 48.7% mAP improvement on ODinW and 59.1% mAP improvement on LVIS compared to state-of-the-art models such as GroundingDINO. We further show that our approach of basing object detection on a set of Web-retrieved exemplars is stable with respect to variations in the exemplars, suggesting a path towards eliminating costly data annotation and training procedures.", "paper_authors": "Mankeerat Sidhu, Hetarth Chopra, Ansel Blume, Jeonghwan Kim, Revanth Gangi Reddy, Heng Ji", "update_time": "2024-09-26", "comments": null, "paper_url": "http://arxiv.org/abs/2409.18733", "paper_id": "2409.18733", "code_url": null}}, "Image Matching": {"2409.18673": {"paper_title": "Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras", "paper_abstract": "Dashboard cameras (dashcams) record millions of driving videos daily, offering a valuable potential data source for various applications, including driving map production and updates. A necessary step for utilizing these dashcam data involves the estimation of camera poses. However, the low-quality images captured by dashcams, characterized by motion blurs and dynamic objects, pose challenges for existing image-matching methods in accurately estimating camera poses. In this study, we propose a precise pose estimation method for dashcam images, leveraging the inherent camera motion prior. Typically, image sequences captured by dash cameras exhibit pronounced motion prior, such as forward movement or lateral turns, which serve as essential cues for correspondence estimation. Building upon this observation, we devise a pose regression module aimed at learning camera motion prior, subsequently integrating these prior into both correspondences and pose estimation processes. The experiment shows that, in real dashcams dataset, our method is 22% better than the baseline for pose estimation in AUC5\\textdegree, and it can estimate poses for 19% more images with less reprojection error in Structure from Motion (SfM).", "paper_authors": "Yipeng Lu, Yifan Zhao, Haiping Wang, Zhiwei Ruan, Yuan Liu, Zhen Dong, Bisheng Yang", "update_time": "2024-09-27", "comments": null, "paper_url": "http://arxiv.org/abs/2409.18673", "paper_id": "2409.18673", "code_url": null}}}